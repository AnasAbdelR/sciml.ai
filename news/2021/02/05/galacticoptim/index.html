<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/hypertext.css"> <link rel=icon  href="/assets/favicon.png"> <title>SciML Ecosystem Update: GalacticOptim, GlobalSensitivity, Tutorials, and Documentation</title> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-2"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-90474609-2'); </script> <header> <h1><b><center>SciML Scientific Machine Learning Software</center></b></h1> <nav> | <a href="/" class=current >Home</a> | <a href="/news/">News</a> | <a href="/roadmap/">Roadmap</a> | <a href="/citing/">Citing</a> | <a href="/showcase/">Showcase</a> | <a href="/challenge/">Challenge Problems</a> | <a href="/community/">Community</a> <hr/> | <a href="/documentation/">Documentation</a> | <a href="/dev/">Dev Programs</a> | <a href="/governance/">Governance</a> | <a href="https://benchmarks.sciml.ai/">Benchmarks</a> | <a href="https://github.com/SciML/">Source Code</a> | <a href="https://numfocus.org/donate-to-sciml">Donate</a> </nav> </header> <div class=franklin-content ><h1 id=sciml_ecosystem_update_galacticoptim_globalsensitivity_tutorials_and_documentation ><a href="#sciml_ecosystem_update_galacticoptim_globalsensitivity_tutorials_and_documentation">SciML Ecosystem Update: GalacticOptim, GlobalSensitivity, Tutorials, and Documentation</a></h1> <p>Another few weeks another few updates. This time around were looking at a few package releases and a bunch of new documentation. Let&#39;s dive right in&#33;</p> <h2 id=galacticoptimjl_a_universal_optimization_interface_for_julia ><a href="#galacticoptimjl_a_universal_optimization_interface_for_julia">GalacticOptim.jl: A Universal Optimization Interface for Julia</a></h2> <p>What would you call a package that combines all that Julia has to offer in optimization? A global optimization package? No, there are many global optimization packages in here, so we&#39;re beyond that&#33; Introducing GalacticOptim.jl: a universal optimization interface for Julia. GalacticOptim.jl sits as an API for calling &#40;almost&#41; any Julia optimization package &#40;and its coverage will continue to improve&#41;. It has a lot of nice high-level tooling that allows for automatically switching choices of optimizers and automatic differentiation across packages. Let&#39;s use ForwardDiff with <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a>&#39;s BFGS:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> GalacticOptim, Optim
rosenbrock(x,p) =  (p[<span class=hljs-number >1</span>] - x[<span class=hljs-number >1</span>])^<span class=hljs-number >2</span> + p[<span class=hljs-number >2</span>] * (x[<span class=hljs-number >2</span>] - x[<span class=hljs-number >1</span>]^<span class=hljs-number >2</span>)^<span class=hljs-number >2</span>
x0 = zeros(<span class=hljs-number >2</span>)
p  = [<span class=hljs-number >1.0</span>,<span class=hljs-number >100.0</span>]

f = OptimizationFunction(rosenbrock, GalacticOptim.AutoForwardDiff())
prob = OptimizationProblem(f, x0, p, lb = [-<span class=hljs-number >1.0</span>,-<span class=hljs-number >1.0</span>], ub = [<span class=hljs-number >1.0</span>,<span class=hljs-number >1.0</span>])
sol = solve(prob,BFGS())</code></pre> <p>But wait, what if we wanted to use <a href="https://github.com/robertfeldt/BlackBoxOptim.jl">BlackBoxOptim.jl</a>? No problem:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> BlackBoxOptim
sol = solve(prob,BBO())</code></pre> <p>This package also directly works with <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> to have a symbolic interface similar to a nonlinear JuMP but on steroids. You can use the &quot;DSL&quot; without using a DSL. How? <code>modelingtoolkitize</code> automatically converts problems to the symbolic form. Let&#39;s generate the Hessian code:</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> ModelingToolkit
sys = modelingtoolkitize(prob)
generate_hessian(sys)[<span class=hljs-number >2</span>]

<span class=hljs-comment >## Returns</span>
:((<span class=hljs-string >var&quot;##MTIIPVar#427&quot;</span>, <span class=hljs-string >var&quot;##MTKArg#424&quot;</span>, <span class=hljs-string >var&quot;##MTKArg#425&quot;</span>)-&gt;<span class=hljs-keyword >begin</span>
          <span class=hljs-meta >@inbounds</span> <span class=hljs-keyword >begin</span>
                  <span class=hljs-keyword >begin</span>
                      (ModelingToolkit.fill_array_with_zero!)(<span class=hljs-string >var&quot;##MTIIPVar#427&quot;</span>)
                      <span class=hljs-keyword >let</span> (x₁, x₂, α₁, α₂) = (<span class=hljs-string >var&quot;##MTKArg#424&quot;</span>[<span class=hljs-number >1</span>], <span class=hljs-string >var&quot;##MTKArg#424&quot;</span>[<span class=hljs-number >2</span>], <span class=hljs-string >var&quot;##MTKArg#425&quot;</span>[<span class=hljs-number >1</span>], <span class=hljs-string >var&quot;##MTKArg#425&quot;</span>[<span class=hljs-number >2</span>])
                          <span class=hljs-string >var&quot;##MTIIPVar#427&quot;</span>[<span class=hljs-number >1</span>] = (+)(<span class=hljs-number >2</span>, (*)(<span class=hljs-number >8</span>, α₂, (^)(x₁, <span class=hljs-number >2</span>)), (*)(-<span class=hljs-number >4</span>, α₂, (+)(x₂, (*)(-<span class=hljs-number >1</span>, (^)(x₁, <span class=hljs-number >2</span>)))))
                          <span class=hljs-string >var&quot;##MTIIPVar#427&quot;</span>[<span class=hljs-number >2</span>] = (*)(-<span class=hljs-number >4</span>, x₁, α₂)
                          <span class=hljs-string >var&quot;##MTIIPVar#427&quot;</span>[<span class=hljs-number >3</span>] = (*)(-<span class=hljs-number >4</span>, x₁, α₂)
                          <span class=hljs-string >var&quot;##MTIIPVar#427&quot;</span>[<span class=hljs-number >4</span>] = (*)(<span class=hljs-number >2</span>, α₂)
                      <span class=hljs-keyword >end</span>
                  <span class=hljs-keyword >end</span>
              <span class=hljs-keyword >end</span>
          <span class=hljs-literal >nothing</span>
      <span class=hljs-keyword >end</span>)</code></pre> <p>And there you go. All of ModelingToolkit&#39;s automated parallelization and transformation features are right there at your fingertips. This library is still new so there&#39;s more to add, like bindings to MOI &#40;for IPOPT&#41;, making use of the symbolic information in solver calls, and automatic differentiability.</p> <h2 id=globalsensitivityjl_efficient_differentiable_and_parallelized_gsa ><a href="#globalsensitivityjl_efficient_differentiable_and_parallelized_gsa">GlobalSensitivity.jl: Efficient, Differentiable, and Parallelized GSA</a></h2> <p>GlobalSensitivity.jl is not necessarily too new since some of the functionality did exist within DiffEqSensitivity.jl before, but now it has been given its own package with a bunch of upgrades to become a full-fledged global sensitivity analysis package. It is complete with its won documentation, tutorials, and many new methods. All of the methods allow for batching in a way that exposes parallelism to the user&#33; <a href="https://gsa.sciml.ai/dev/">Check out the new documentation.</a></p> <h2 id=new_diffeqflux_tutorials_bouncing_ball_multiple_networks_and_more ><a href="#new_diffeqflux_tutorials_bouncing_ball_multiple_networks_and_more">New DiffEqFlux Tutorials: Bouncing Ball, Multiple Networks, and More</a></h2> <p>Due to popular request, quite a few new DiffEqFlux tutorials were added. There are tutorials doing <a href="https://diffeqflux.sciml.ai/dev/examples/bouncing_ball/">automatic differentiation through event handling like bouncing ball</a>, <a href="https://diffeqflux.sciml.ai/dev/examples/stiff_ode_fit/">parameter estimation techniques for highly stiff systems</a>, and more. While these aren&#39;t new functionalities, it&#39;s highlighting them in a new light that hopefully will help you make use of them effectively&#33;</p> <h2 id=new_uncertainty_quantification_tutorial_gpu-acclerated_bayesian-koopman_uq ><a href="#new_uncertainty_quantification_tutorial_gpu-acclerated_bayesian-koopman_uq">New Uncertainty Quantification Tutorial: GPU-Acclerated Bayesian-Koopman UQ</a></h2> <p>A new tutorial was added on <a href="https://tutorials.sciml.ai/html/DiffEqUncertainty/03-GPU_Bayesian_Koopman.html">GPU-accelerated Bayesian Koopman uncertainty quantification</a>. Together it shows how to estimate the uncertainty distributions of parameters and then quickly compute probabilistic statements about the solution in a GPU-accelerated fashion that&#39;s order of magnitude faster than Monte Carlo. The steps are:</p> <ol> <li><p>Parameter estimation with uncertainty with Bayesian differential equations by integrating the differentiable differential equation solvers with the Turing.jl library.</p> <li><p>Fast calculation of probabilistic estimates of differential equation solutions with parametric uncertainty using the Koopman expectation.</p> <li><p>GPU-acceleration of batched differential equation solves.</p> </ol> <p>Check the tutorial for more information&#33;</p> <h2 id=new_docs_diffeqbayes_diffeqparamestim_diffeqoperators ><a href="#new_docs_diffeqbayes_diffeqparamestim_diffeqoperators">New Docs: DiffEqBayes, DiffEqParamEstim, DiffEqOperators</a></h2> <p>The core DifferentialEquations.jl documentation was cleaned up with some of the auxillary pieces moved out. As part of that, more repositories around the ecosystem go their own documentation. <a href="https://diffeqparamestim.sciml.ai/dev/">DiffEqParamEstim.jl</a> is easy and automated parameter inference for differential equations. <a href="https://diffeqbayes.sciml.ai/dev/">DiffEqBayes.jl</a> is easy Bayesian inference for differential equations. And <a href="https://diffeqoperators.sciml.ai/dev/">DiffEqOperators.jl</a> is our automated finite difference discretization library. Now that these docs are decoupled from the main docs, they are free to grow and flesh out their descriptions. The main pages of DifferentialEquations.jl now is a comparison of the different choices in the ecosystem with links to the companion package documentations. Hopefully this will make it easier to guide users towards DiffEqFlux and Turing, and understand when the other offerings are useful.</p> <div class=page-foot > <div class=copyright > Website powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia</a> programming language. </div> </div> </div>