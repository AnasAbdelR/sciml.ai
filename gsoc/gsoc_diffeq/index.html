<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <meta property="og:title" content=SciML > <meta property="og:description" content="Open Source Software for Scientific Machine Learning"> <meta property="og:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta property="og:url" content="https://sciml.ai"> <meta name="twitter:title" content=SciML > <meta name="twitter:description" content="Open Source Software for Scientific Machine Learning"> <meta name="twitter:image" content="https://sciml.ai/assets/SciMLGitHubPreview.png"> <meta name="twitter:card" content=summary_large_image > <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/hypertext.css"> <link rel=icon  href="/assets/favicon.png"> <title>SciML Numerical Differential Equations Projects – Google Summer of Code</title> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90474609-2"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-90474609-2'); </script> <header> <h1><b><center>SciML Scientific Machine Learning Software</center></b></h1> <nav> | <a href="/" class=current >Home</a> | <a href="/news/">News</a> | <a href="/roadmap/">Roadmap</a> | <a href="/citing/">Citing</a> | <a href="/showcase/">Showcase</a> | <a href="/challenge/">Challenge Problems</a> | <a href="/community/">Community</a> <hr/> | <a href="/documentation/">Documentation</a> | <a href="/dev/">Dev Programs</a> | <a href="/governance/">Governance</a> | <a href="https://benchmarks.sciml.ai/">Benchmarks</a> | <a href="https://github.com/SciML/">Source Code</a> | <a href="https://numfocus.org/donate-to-sciml">Donate</a> </nav> </header> <div class=franklin-content ><h1 id=sciml_numerical_differential_equations_projects_google_summer_of_code ><a href="#sciml_numerical_differential_equations_projects_google_summer_of_code" class=header-anchor >SciML Numerical Differential Equations Projects – Google Summer of Code</a></h1> <h2 id=native_julia_ode_sde_dae_dde_and_spde_solvers ><a href="#native_julia_ode_sde_dae_dde_and_spde_solvers" class=header-anchor >Native Julia ODE, SDE, DAE, DDE, and &#40;S&#41;PDE Solvers</a></h2> <p>The DifferentialEquations.jl ecosystem has an extensive set of state-of-the-art methods for solving differential equations hosted by the <a href="https://sciml.ai/">SciML Scientific Machine Learning Software Organization</a>. By mixing native methods and wrapped methods under the same dispatch system, <a href="https://arxiv.org/abs/1807.06430">DifferentialEquations.jl serves both as a system to deploy and research the most modern efficient methodologies</a>. While most of the basic methods have been developed and optimized, many newer methods need high performance implementations and real-world tests of their efficiency claims. In this project students will be paired with current researchers in the discipline to get a handle on some of the latest techniques and build efficient implementations into the &#42;DiffEq libraries &#40;OrdinaryDiffEq.jl, StochasticDiffEq.jl, DelayDiffEq.jl&#41;. Possible families of methods to implement are:</p> <div class=tight-list ><ul> <li><p>Global error estimating ODE solvers</p> <li><p>Implicit-Explicit &#40;IMEX&#41; Methods</p> <li><p>Geometric &#40;exponential&#41; integrators</p> <li><p>Low memory Runge-Kutta methods</p> <li><p>Multistep methods specialized for second order ODEs &#40;satellite simulation&#41;</p> <li><p>Parallel &#40;multithreaded&#41; extrapolation &#40;both explicit and implicit&#41;</p> <li><p>Parallel Implicit Integrating Factor Methods &#40;PDEs and SPDEs&#41;</p> <li><p>Parallel-in-time ODE Methods</p> <li><p>Rosenbrock-W methods</p> <li><p>Approximate matrix factorization</p> <li><p>Runge-Kutta-Chebyshev Methods &#40;high stability RK methods&#41;</p> <li><p>Fully Implicit Runge-Kutta &#40;FIRK&#41; methods</p> <li><p>Anderson Acceleration</p> <li><p>Boundary value problem &#40;BVP&#41; solvers like MIRK and collocation methods</p> <li><p>BDF methods for differential-algebraic equations &#40;DAEs&#41;</p> <li><p>Methods for stiff stochastic differential equations</p> </ul></div> <p>Many of these methods are the basis of high-efficiency partial differential equation &#40;PDE&#41; solvers and are thus important to many communities like computational fluid dynamics, mathematical biology, and quantum mechanics.</p> <p>This project is good for both software engineers interested in the field of numerical analysis and those students who are interested in pursuing graduate research in the field.</p> <p><strong>Recommended Skills</strong>: Background knowledge in numerical analysis, numerical linear algebra, and the ability &#40;or eagerness to learn&#41; to write fast code.</p> <p><strong>Expected Results</strong>: Contributions of production-quality solver methods.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a>, <a href="https://github.com/YingboMa">Yingbo Ma</a>, <a href="https://github.com/kanav99">Kanav Gupta</a> and <a href="https://github.com/utkarsh530">Utkarsh</a></p> <h2 id=improvements_to_physics-informend_neural_networks_pinn_for_solving_differential_equations ><a href="#improvements_to_physics-informend_neural_networks_pinn_for_solving_differential_equations" class=header-anchor >Improvements to Physics-Informend Neural networks &#40;PINN&#41; for solving differential equations</a></h2> <p>Neural networks can be used as a method for efficiently solving difficult partial differential equations. Efficient implementations of physics-informed machine learning from recent papers are being explored as part of the <a href="https://github.com/SciML/NeuralPDE.jl">NeuralPDE.jl</a> package. The <a href="https://github.com/SciML/NeuralPDE.jl/issues">issue tracker</a> contains links to papers which would be interesting new neural network based methods to implement and benchmark against classical techniques.</p> <p><strong>Recommended Skills</strong>: Background knowledge in numerical analysis and machine learning.</p> <p><strong>Expected Results</strong>: New neural network based solver methods.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a> and <a href="https://github.com/KirillZubov">Kirill Zubov</a></p> <h2 id=performance_enhancements_for_differential_equation_solvers ><a href="#performance_enhancements_for_differential_equation_solvers" class=header-anchor >Performance enhancements for differential equation solvers</a></h2> <p>Wouldn&#39;t it be cool to have had a part in the development of widely used efficient differential equation solvers? DifferentialEquations.jl has a wide range of existing methods and <a href="https://github.com/SciML/DiffEqBenchmarks.jl">an extensive benchmark suite</a> which is used for tuning the methods for performance. Many of its methods are already the fastest in their class, but there is still a lot of performance enhancement work that can be done. In this project you can learn the details about a wide range of methods and dig into the optimization of the algorithm&#39;s strategy and the implementation in order to improve benchmarks. Projects that could potentially improve the performance of the full differential equations ecosystem include:</p> <div class=tight-list ><ul> <li><p>Alternative adaptive stepsize techniques and step optimization</p> <li><p>Pointer swapping tricks</p> <li><p>Quasi-Newton globalization and optimization</p> <li><p>Cache size reductions</p> <li><p>Enhanced within-method multithreading, distributed parallelism, and GPU usage</p> <li><p>Improved automated method choosing</p> <li><p>Adaptive preconditioning on large-scale &#40;PDE&#41; discretizations</p> </ul></div> <p><strong>Recommended Skills</strong>: Background knowledge in numerical analysis, numerical linear algebra, and the ability &#40;or eagerness to learn&#41; to write fast code.</p> <p><strong>Expected Results</strong>: Improved benchmarks to share with the community.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a> and <a href="https://github.com/YingboMa">Yingbo Ma</a></p> <h2 id=discretizations_of_partial_differential_equations ><a href="#discretizations_of_partial_differential_equations" class=header-anchor >Discretizations of partial differential equations</a></h2> <p>There are two ways to approach libraries for partial differential equations &#40;PDEs&#41;: one can build &quot;toolkits&quot; which enable users to discretize any PDE but require knowledge of numerical PDE methods, or one can build &quot;full-stop&quot; PDE solvers for specific PDEs. There are many different ways solving PDEs could be approached, and here are some ideas for potential projects:</p> <div class=tight-list ><ol> <li><p>Automated PDE discretization tooling. We want users to describe a PDE in its mathematical form and automate the rest of the solution process. See <a href="https://github.com/SciML/DifferentialEquations.jl/issues/469">this issue for details</a>.</p> <li><p>Enhancement of existing tools for discretizing PDEs. The finite differencing &#40;FDM&#41; library <a href="https://github.com/SciML/MethodOfLines.jl">MethodOfLines.jl</a> could be enhanced to allow non-uniform grids or composition of operators. The finite element method &#40;FEM&#41; library <a href="https://github.com/SciML/FEniCS.jl">FEniCS.jl</a> could wrap more of the FEniCS library.</p> <li><p>Full stop solvers of common fluid dynamical equations, such as diffusion-advection-convection equations, or of hyperbolic PDEs such as the Hamilton-Jacobi-Bellman equations would be useful to many users.</p> <li><p>Using stochastic differential equation &#40;SDE&#41; solvers to efficiently &#40;and highly parallel&#41; approximate certain PDEs.</p> <li><p>Development of ODE solvers for more efficiently solving specific types of PDE discretizations. See the &quot;Native Julia solvers for ordinary differential equations&quot; project.</p> </ol></div> <p><strong>Recommended Skills</strong>: Background knowledge in numerical methods for solving differential equations. Some basic knowledge of PDEs, but mostly a willingness to learn and a strong understanding of calculus and linear algebra.</p> <p><strong>Expected Results</strong>: A production-quality PDE solver package for some common PDEs.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a></p> <h2 id=tools_for_global_sensitivity_analysis ><a href="#tools_for_global_sensitivity_analysis" class=header-anchor >Tools for global sensitivity analysis</a></h2> <p>Global Sensitivity Analysis is a popular tool to assess the effect that parameters have on a differential equation model. A good introduction <a href="https://discovery.ucl.ac.uk/id/eprint/19896/">can be found in this thesis</a>. Global Sensitivity Analysis tools can be much more efficient than Local Sensitivity Analysis tools, and give a better view of how parameters affect the model in a more general sense. The goal of this project would be to implement more global sensitivity analysis methods like the eFAST method into <a href="https://github.com/SciML/GlobalSensitivity.jl">GlobalSensitivity.jl</a> which can be used with any differential equation solver on the common interface.</p> <p><strong>Recommended Skills</strong>: An understanding of how to use DifferentialEquations.jl to solve equations.</p> <p><strong>Expected Results</strong>: Efficient functions for performing global sensitivity analysis.</p> <p><strong>Mentors</strong>: <a href="https://github.com/ChrisRackauckas">Chris Rackauckas</a> and <a href="https://github.com/Vaibhavdixit02">Vaibhav Dixit</a></p> <div class=page-foot > <div class=copyright > Website powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia</a> programming language. </div> <div class=copyright > Edit on <a href="https://github.com/SciML/sciml.ai">GitHub</a> </div> </div> </div>